{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rust_segmentation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1ZgP3SQW8Y4ZFakQau1Q8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vlad-Ozik/rust_segmentation/blob/main/rust_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCG8vHK2H9Sg"
      },
      "source": [
        "!pip install segmentation-models-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cl_UCPDKFwg"
      },
      "source": [
        "!pip install -U git+https://github.com/albu/albumentations --no-cache-dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk-5rSylKH3T"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy58q8xDK-da"
      },
      "source": [
        "import os\n",
        "from typing import Union, List\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOVkE7OyRkcv"
      },
      "source": [
        "def visualize(**images):\n",
        "    \"\"\"PLot images in one row.\"\"\"\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKHWQ5MARAkG"
      },
      "source": [
        "# **Prepare data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scv6hqhfVxOQ"
      },
      "source": [
        "# Create new folders for splited images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m62rrXQEO4RT"
      },
      "source": [
        "DATA_DIR = 'gdrive/MyDrive/test_task/rust_dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0IN6bBRP6R_"
      },
      "source": [
        "x_train_dir = os.path.join(DATA_DIR, 'train')\n",
        "y_train_dir = os.path.join(DATA_DIR, 'trainannot')\n",
        "\n",
        "x_valid_dir = os.path.join(DATA_DIR, 'val')\n",
        "y_valid_dir = os.path.join(DATA_DIR, 'valannot')\n",
        "\n",
        "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'testannot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIeciG_CLQBn"
      },
      "source": [
        "if not os.path.exists(x_train_dir):\n",
        "    print('Prepare folders...')\n",
        "    os.system(f\"mkdir {x_train_dir}\")\n",
        "    os.system(f\"mkdir {y_train_dir}\")\n",
        "    os.system(f\"mkdir {x_valid_dir}\")\n",
        "    os.system(f\"mkdir {y_valid_dir}\")\n",
        "    os.system(f\"mkdir {x_test_dir}\")\n",
        "    os.system(f\"mkdir {y_test_dir}\")\n",
        "    print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNVgPfWxRxCr"
      },
      "source": [
        "# Splitting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split(img: np.array, mask: np.array, split_HW: [int, int]) -> List[list]:\n",
        "  img_height, img_width = img.shape[:2]\n",
        "  y, x = 0, 0\n",
        "  masks_crop = list()\n",
        "  images_crop = list()\n",
        "  for i in range(img_height//split_HW[0]):\n",
        "      for j in range(img_width//split_HW[1]):      \n",
        "          mask_crop = mask[y:y+split_HW[0], x:x+split_HW[1]]\n",
        "          # if mask is exist for crop\n",
        "          if mask_crop.max() == 255:\n",
        "            img_crop = img[y:y+split_HW[0], x:x+split_HW[1]]\n",
        "            y, x = split_HW[0]*i, split_HW[1]*j\n",
        "            masks_crop.append(mask_crop)\n",
        "            images_crop.append(img_crop)\n",
        "          else:\n",
        "            y, x = split_HW[0]*i, split_HW[1]*j\n",
        "  return images_crop, masks_crop"
      ],
      "metadata": {
        "id": "GMZKZfg3plAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mjmq5vwQsiZ"
      },
      "source": [
        "image_names = [name.split('.')[0] for name in os.listdir(DATA_DIR+'image/')]\n",
        "try:\n",
        "  # split images 80% train, 15% test, 5% val\n",
        "  image_names = np.split(image_names, [int(.8*len(image_names)), int(.85*len(image_names))])\n",
        "  folders = [['train', 'trainannot'],\n",
        "             ['val', 'valannot'],\n",
        "             ['test', 'testannot']]\n",
        "  for i, imgs_name in enumerate(image_names):\n",
        "    for im_name in imgs_name:\n",
        "      print(im_name)\n",
        "      img = cv2.imread(os.path.join(DATA_DIR, 'image', im_name+\".JPG\"))\n",
        "      mask = cv2.imread(os.path.join(DATA_DIR, 'mask', im_name+\".png\"))\n",
        "      images, masks = split(img, mask, [600, 800])\n",
        "      j = 0\n",
        "      for image, mask in zip(images, masks):\n",
        "        cv2.imwrite(os.path.join(DATA_DIR, folders[i][0], im_name+f\"_{j}.png\"), image)\n",
        "        cv2.imwrite(os.path.join(DATA_DIR, folders[i][1], im_name+f\"_{j}_mask.png\"), mask)\n",
        "        j += 1\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "  print(f\"Image Not Found! {e}\")\n",
        "finally:\n",
        "  print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader and augmentations"
      ],
      "metadata": {
        "id": "H_bjCTZVU6gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset as BaseDataset"
      ],
      "metadata": {
        "id": "PHcN9DdXrjrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBeN5a36Qtwg"
      },
      "source": [
        "class Dataset(BaseDataset):\n",
        "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
        "    \n",
        "    Args:\n",
        "        images_dir (str): path to images folder\n",
        "        masks_dir (str): path to segmentation masks folder\n",
        "        class_values (list): values of classes to extract from segmentation mask\n",
        "        augmentation (albumentations.Compose): data transfromation pipeline \n",
        "            (e.g. flip, scale, etc.)\n",
        "        preprocessing (albumentations.Compose): data preprocessing \n",
        "            (e.g. noralization, shape manipulation, etc.)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "            self, \n",
        "            images_dir, \n",
        "            masks_dir,\n",
        "            augmentation=None, \n",
        "            preprocessing=None,\n",
        "    ):\n",
        "        self.ids = os.listdir(images_dir)\n",
        "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
        "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
        "        \n",
        "        # convert str names to class values on masks        \n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # read data\n",
        "        image = cv2.imread(self.images_fps[i])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(self.masks_fps[i].replace('.png', '_mask.png'), cv2.IMREAD_GRAYSCALE)\n",
        "        \n",
        "        gb_mask = cv2.GaussianBlur(mask, (3,3), 7)\n",
        "        thrash = cv2.threshold(gb_mask, 3, 255, cv2.THRESH_BINARY)[1]\n",
        "        kernel = np.ones((5,5),np.uint8)\n",
        "        thrash = cv2.morphologyEx(thrash, cv2.MORPH_OPEN, kernel)\n",
        "        thrash = cv2.morphologyEx(thrash, cv2.MORPH_CLOSE, kernel)\n",
        "        thrash[thrash>0] = 1\n",
        "        mask = thrash[:, :, np.newaxis].astype('float')\n",
        "        \n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "        \n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "            \n",
        "        return image, mask\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset(x_valid_dir, y_valid_dir)\n",
        "\n",
        "image, mask = dataset[1] # get some sample\n",
        "\n",
        "visualize(\n",
        "    image=image, \n",
        "    cars_mask=mask.squeeze(),\n",
        ")"
      ],
      "metadata": {
        "id": "7Yt5xfQySpMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as albu\n"
      ],
      "metadata": {
        "id": "hRkpMRsxSw8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "\n",
        "        albu.HorizontalFlip(p=0.5),\n",
        "\n",
        "        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
        "\n",
        "        albu.PadIfNeeded(min_height=320, min_width=320, always_apply=True, border_mode=0),\n",
        "        albu.CropNonEmptyMaskIfExists(height=320, width=320, always_apply=True),\n",
        "\n",
        "        albu.IAAAdditiveGaussianNoise(p=0.2),\n",
        "        albu.IAAPerspective(p=0.5),\n",
        "\n",
        "        albu.OneOf(\n",
        "            [\n",
        "                albu.CLAHE(p=1),\n",
        "                albu.RandomBrightness(p=1),\n",
        "                albu.RandomGamma(p=1),\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "\n",
        "        albu.OneOf(\n",
        "            [\n",
        "                albu.IAASharpen(p=1),\n",
        "                albu.Blur(blur_limit=3, p=1),\n",
        "                albu.MotionBlur(blur_limit=3, p=1),\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "\n",
        "        albu.OneOf(\n",
        "            [\n",
        "                albu.RandomContrast(p=1),\n",
        "                albu.HueSaturationValue(p=1),\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "    ]\n",
        "    return albu.Compose(train_transform)\n",
        "\n",
        "\n",
        "def to_tensor(x, **kwargs):\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "\n",
        "def get_preprocessing(preprocessing_fn):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "    \n",
        "    Args:\n",
        "        preprocessing_fn (callbale): data normalization function \n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    _transform = [\n",
        "        albu.Lambda(image=preprocessing_fn),\n",
        "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
        "    ]\n",
        "    return albu.Compose(_transform)"
      ],
      "metadata": {
        "id": "kficqEHPSzDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_validation_augmentation():\n",
        "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "    test_transform = [\n",
        "        albu.Resize(384, 480, always_apply= True),\n",
        "    ]\n",
        "    return albu.Compose(test_transform)"
      ],
      "metadata": {
        "id": "jpMKugwiS3TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_dataset = Dataset(\n",
        "    x_valid_dir, \n",
        "    y_valid_dir, \n",
        "    augmentation=get_training_augmentation(), \n",
        ")\n",
        "\n",
        "# same image with different random transforms\n",
        "for i in range(3):\n",
        "    image, mask = augmented_dataset[i]\n",
        "    visualize(image=image, mask=mask.squeeze())"
      ],
      "metadata": {
        "id": "eGIb1bjmS5qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "gvbfOLrtVOtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import segmentation_models_pytorch as smp"
      ],
      "metadata": {
        "id": "Dbx6GjovTac2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER = 'se_resnext50_32x4d'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "CLASSES = ['rust',]\n",
        "ACTIVATION = 'sigmoid'\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "model = smp.FPN(\n",
        "    encoder_name=ENCODER, \n",
        "    encoder_weights=ENCODER_WEIGHTS, \n",
        "    activation=ACTIVATION,\n",
        ")\n",
        "\n",
        "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
      ],
      "metadata": {
        "id": "ALc0OrNJUU4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(\n",
        "    x_train_dir, \n",
        "    y_train_dir, \n",
        "    augmentation=get_training_augmentation(), \n",
        "    preprocessing=get_preprocessing(preprocessing_fn)\n",
        ")\n",
        "\n",
        "valid_dataset = Dataset(\n",
        "    x_valid_dir, \n",
        "    y_valid_dir, \n",
        "    augmentation=get_validation_augmentation(), \n",
        "    preprocessing=get_preprocessing(preprocessing_fn)\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=12)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "id": "trYDOEVSWwAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = smp.utils.losses.DiceLoss()\n",
        "metrics = [\n",
        "    smp.utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "optimizer = torch.optim.RAdam([ \n",
        "    dict(params=model.parameters(), lr=0.0001),\n",
        "])"
      ],
      "metadata": {
        "id": "7QT6urfAW2x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "ZWjsi998W_xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, mask = train_dataset[1]\n",
        "mask.shape"
      ],
      "metadata": {
        "id": "es4mzlrEXCEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_score = 0\n",
        "\n",
        "for i in range(0, 40):\n",
        "    \n",
        "    print('\\nEpoch: {}'.format(i))\n",
        "    train_logs = train_epoch.run(train_loader)\n",
        "    valid_logs = valid_epoch.run(valid_loader)\n",
        "    \n",
        "    # do something (save model, change lr, etc.)\n",
        "    if max_score < valid_logs['iou_score']:\n",
        "        max_score = valid_logs['iou_score']\n",
        "        torch.save(model, './best_model_rust_seg.pth')\n",
        "        print('Model saved!')\n",
        "        \n",
        "    if i == 25:\n",
        "        optimizer.param_groups[0]['lr'] = 1e-5\n",
        "        print('Decrease decoder learning rate to 1e-5!')"
      ],
      "metadata": {
        "id": "oTneXiUTXJtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test best saved model**"
      ],
      "metadata": {
        "id": "ctbxcmhRVMpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = torch.load('/content/best_model_rust_seg.pth')"
      ],
      "metadata": {
        "id": "4s7Uc46LXMTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Dataset(\n",
        "    x_test_dir, \n",
        "    y_test_dir, \n",
        "    augmentation=get_validation_augmentation(), \n",
        "    preprocessing=get_preprocessing(preprocessing_fn),\n",
        ")\n"
      ],
      "metadata": {
        "id": "iMzaudGOU7Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(test_dataset)"
      ],
      "metadata": {
        "id": "o6IYFGeMU-0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_epoch = smp.utils.train.ValidEpoch(\n",
        "    model=best_model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        ")\n",
        "\n",
        "logs = test_epoch.run(test_dataloader)"
      ],
      "metadata": {
        "id": "_sD9PIzNVBci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_vis = Dataset(\n",
        "    x_test_dir, y_test_dir, \n",
        ")"
      ],
      "metadata": {
        "id": "J5dyPrILVEoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    n = np.random.choice(len(test_dataset))\n",
        "    \n",
        "    image_vis = test_dataset_vis[n][0].astype('uint8')\n",
        "    image, gt_mask = test_dataset[n]\n",
        "    \n",
        "    gt_mask = gt_mask.squeeze()\n",
        "    \n",
        "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
        "    pr_mask = best_model.predict(x_tensor)\n",
        "    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n",
        "        \n",
        "    visualize(\n",
        "        image=image_vis, \n",
        "        ground_truth_mask=gt_mask, \n",
        "        predicted_mask=pr_mask\n",
        "    )"
      ],
      "metadata": {
        "id": "6py7w0IvVTDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jGD8CjVYVV8q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}